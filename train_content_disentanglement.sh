#!/bin/bash  
PRETRAINED_MODEL_PATH="stabilityai/stable-diffusion-xl-base-1.0"  
INSTANCE_DATA_DIR="example/content"
RESOLUTION=512  
RANK=64
TRAIN_BATCH_SIZE=1  
LEARNING_RATE="1e-5"  
LR_SCHEDULER="constant"  
LR_WARMUP_STEPS=0  
MAX_TRAIN_STEPS=1500  
CHECKPOINTING_STEPS=1500  
SEED=0

# content enchance prompt (generated by llm such as gpt4o or manually)
# placeholders have been integrated into the code, eliminating the need for re-injection.
# * is the content/ID placeholder.
CONTENT_PROMPT="A woman with long, flowing blonde hair, wearing a dark sweater in photo style."
OUTPUT_DIR="lora/content"
echo $INSTANCE_DATA_DIR
echo $OUTPUT_DIR
echo $CONTENT_PROMPT

# 启动训练  
python3 -m accelerate.commands.launch train_content_disentanglement.py \
    --pretrained_model_name_or_path="$PRETRAINED_MODEL_PATH" \
    --instance_data_dir="$INSTANCE_DATA_DIR" \
    --output_dir="$OUTPUT_DIR" \
    --instance_prompt="$CONTENT_PROMPT" \
    --resolution="$RESOLUTION" \
    --rank="$RANK" \
    --train_batch_size="$TRAIN_BATCH_SIZE" \
    --learning_rate="$LEARNING_RATE" \
    --embedding_manager_lr=1e-5  \
    --train_text_encoder \
    --lr_scheduler="$LR_SCHEDULER" \
    --lr_warmup_steps="$LR_WARMUP_STEPS" \
    --max_train_steps="$MAX_TRAIN_STEPS" \
    --checkpointing_steps="$CHECKPOINTING_STEPS" \
    --seed="$SEED" \
    --gradient_checkpointing \
    --use_8bit_adam \
    --mixed_precision=fp16  